{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Projeto 1</center>\n",
    "# <center>Fake News Detection</center>\n",
    "___\n",
    "Nesse notebook serão descritos todos os passos e métodos utilizados para a resolução do projeto.\n",
    "___\n",
    "\n",
    "# <center> Objetivos do projeto </center>\n",
    "- Utilização de método para análise de textos\n",
    "- Aprimoramento de métodos de Machine Learning\n",
    "___\n",
    "\n",
    "## Conteúdo\n",
    "1. [Importação](#1)\n",
    "2. [Análise Exploratória](#2)\n",
    "3. [Pipeline Inicial](#3)\n",
    "4. [Grid Search - Best Parameters](#4)\n",
    "5. [Resultados Finais](#5)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\"></a>\n",
    "## 1. Importação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2\"></a>\n",
    "## 2. Análise Exploratória"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Dados do projeto\n",
    "\n",
    "O projeto foi proposto pela Data Flair Training como projeto de inicialização em conhecimentos de Machine Learning. O projeto e os demais encontram-se [neste link](https://data-flair.training/blogs/data-science-project-ideas/). <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/news.csv\", sep=\",\", index_col=0)\n",
    "df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Dicionário das variáveis\n",
    "\n",
    "- **title**: Título da Noticia\n",
    "- **text**: Texto da Noticia\n",
    "- **label**: Classificação da Noticia como sendo FAKE ou REAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dados não possuem valores faltantes nas colunas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Tamanho dos textos\n",
    "\n",
    "O método trabalhado nesse projeto será o **Tfidfvectorizer**, um algoritmo que transformar texto em uma representação significativa de números, usado assim, para o treinamento dos algoritmos de Machine Learning e suas previsões.\n",
    "\n",
    "Assim, a checagem de tamanho dos textos será utilizado para evidenciar tendências de quantidade de caracteres e possivelmente textos vazios no conjunto de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = []\n",
    "[length.append(len(str(text))) for text in df['text']]\n",
    "df['length'] = length\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.length.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os valores mínimos e máximos revelam alguns *outliers* que estudados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Número de artigos entre [0, 20]: ', len(df[df.length.between(0, 20)]))\n",
    "print(df['text'][df.length.between(0, 20)])\n",
    "\n",
    "print('Número de artigos entre [50000, max]: ', len(df[df.length.between(50000, max(df.length))]))\n",
    "print(df['text'][df.length.between(50000, max(df.length))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df['text'][df.length.between(0, 20) | df.length.between(50000, max(df.length))].index, axis=0)\n",
    "df.length.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No total, 44 registros foram retirados do conjunto de dados por serem considerados *outliers*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Limpeza dos dados\n",
    "\n",
    "Os textos presentes na base de dados possuem vários caracteres que não agregam nenhuma informação adicional para o modelo durante seu processo de aprendizado, já que serão reconhecidas apenas palavras.\n",
    "\n",
    "Assim será realizado uma limpeza da coluna *df.text* removendo esses caracteres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.text[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df.text.apply(lambda text: ' '.join(re.findall('\\w+',text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.text[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"3\"></a>\n",
    "## 3. Pipeline Inicial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Preparação dos dados\n",
    "\n",
    "A preparação dos dados será constituída acerca da separação dos dados de treinamento (80%) e de teste (20%) do conjunto de dados disponíveis na base.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.loc[:, df.columns != \"label\"]\n",
    "y = df.loc[:, df.columns == \"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X[\"text\"], y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Transformação dos dados\n",
    "\n",
    "Para o método Tfidfvectorizer utilizado, alguns parâmetros são necessários, como:\n",
    "- **analyzer**: Especifica o grau de granularidade que o texto deve ser subdivido durante a análise (palavra ou partes de palavras)\n",
    "- **stop_words**: Especifica a lista de palavras que devem ser desconsideradas já que se presume não serem informativas na representação do conteúdo do texto, e assim podem ser removidas para evitar que sejam interpretadas como um sinal de previsão.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfvectorizer = TfidfVectorizer(analyzer='word', stop_words= 'english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Foram usados as recomendações obtidas na documentação do método presente em: [**sklearn.feature_extraction.text.TfidfVectorizer**](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_train = tfidfvectorizer.fit_transform(X_train)\n",
    "tfidf_test = tfidfvectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicação do método no conjunto de dados de treinamento, e replicação do mesmo processo no conjunto de dados de teste."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. PassiveAgressiveClassifier\n",
    "\n",
    "Para o objetivo do projeto, a classificação das notícia como sendo Fake (Falsa) ou Real, através da análise de textos de noticias, trata-se de um problema de Natural Languague Processing (NLP) ou Linguaguem de Processamento Natural.\n",
    "Para isso, o método utilizado será o PassiveAgressiveClassifier, muito recomendado para a prática de classificação e análise de textos. No método os seguintes parâmetros serão utilizados:\n",
    "- **C**: Tamanho máximo do passo (regularização), sendo o padrão de 1.0.\n",
    "- **loss**: A função de perda a ser utilizada (hinge, squared_hinge).\n",
    "- **max_iter**: O número máximo de passagens sobre os dados de treinamento (também conhecido como épocas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo inicial para avaliação\n",
    "model = PassiveAggressiveClassifier(C=0.5, loss=\"hinge\", max_iter=5, random_state=42)\n",
    "  \n",
    "# Treinamento do modelo com o conjunto de dados de treinamento\n",
    "model.fit(tfidf_train, y_train)\n",
    "  \n",
    "# Realização as predições no conjunto de dados de teste\n",
    "test_pred = model.predict(tfidf_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O modelo inicial com parâmetros aleatórios será utilizado de compreensão se o modelo adaptasse ou não a base de dados. Por fim, os métodos de avaliação dos resultados do modelo serão a **Acurácia** (grau de acertividade do modelo) e a **Matrix de Confusão** para visualização do quantidade de previsões assertivas e incorretas em cada classe de saída."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliação do modelo\n",
    "print(f\"Acurácia Dados de Teste: {accuracy_score(y_test, test_pred) * 100} %\\n\\n\")  \n",
    "  \n",
    "print(f\"Matrix de Confusão: \\n\\n{confusion_matrix(y_test, test_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para um cenário inicial aleatório, o modelo obteve ótimos resultados com acurácia de **93.48%** de previsões corretas. Porém, os parâmetros foram estipulados de forma aleátória, o que demonstra que possa existir um conjunto de parâmetros que melhore os resultados do modelo ainda mais."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"4\"></a>\n",
    "## 4. Grid Search - Best Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O Grid Search é uma técnica de ajuste que tenta calcular os valores ótimos dos parâmetros de um modelo de aprendizado afim de encontrar os melhores resultados da avaliação do modelo.\n",
    "\n",
    "É um método exaustivo, e muitas vezes computacionalmente inviável por requerer um longo período de análise, ele propõe determinar o melhor conjunto de parâmetros do modelo durante o treinamento do modelo, selecionando o conjunto que obtiver melhores resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definição do conjunto de parâmetros e valores a serem testados\n",
    "param_grid = {'C' : [0.003, 0.01, 0.03, 0.1], 'loss': ['hinge', 'squared_hinge'], 'max_iter': [5, 10, 30, 100, 300]}\n",
    "\n",
    "# Inicialização e treinamento do método\n",
    "grid_search = GridSearchCV(model, param_grid)\n",
    "grid_search.fit(tfidf_train, y_train)\n",
    "\n",
    "# Visualização do melhor conjunto de parâmetros\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora, é possível re-executar o método com o conjunto de parâmetros encontrados pelo método Grid Search, e analisar se houve ou não melhoria nos resultados obtidos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"5\"></a>\n",
    "## 5. Resultados Finais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PassiveAggressiveClassifier(C= 0.03, loss= 'hinge', max_iter= 100, random_state=42)\n",
    "  \n",
    "# Treinamento do modelo com o conjunto de dados de treinamento\n",
    "model.fit(tfidf_train, y_train)\n",
    "  \n",
    "# Realização as predições no conjunto de dados de teste\n",
    "test_pred = model.predict(tfidf_test)\n",
    "  \n",
    "# Avaliação do modelo\n",
    "print(f\"Acurácia Dados de Teste: {accuracy_score(y_test, test_pred) * 100} %\\n\\n\")  \n",
    "  \n",
    "print(f\"Matrix de Confusão: \\n\\n{confusion_matrix(y_test, test_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observa-se uma melhor performance do modelo em suas previsões utilizando o conjunto de parâmetros definidos pelo método Grid Search como sendo os melhores dentre as opções. Assim o modelo final é computado com uma acurácia de **93.72%**. Ademais, é demonstrado a Matrix de Confusão utilizando a biblioteca de plotagem gráfica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Fake', 'Real']\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(confusion_matrix(y_test, test_pred), annot=True, cmap=\"YlGnBu\", fmt=\".1f\", xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel('Predicted Class')\n",
    "plt.ylabel('Original Class')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
